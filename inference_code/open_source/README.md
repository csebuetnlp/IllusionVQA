<h3>Usage</h3>

Clone the repository and run
`
./run_inference.sh
`

Three models will be downloaded (~100GB). Takes 80GB VRAM to run. Results will be saved in `results.zip`
